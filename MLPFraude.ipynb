{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 8 – MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importatation de modules commun\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pour la énération de seed\n",
    "np.random.seed(4)\n",
    "\n",
    "# pur l'afficae de figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture des deux datasets Train_FraudeAA et Test_FraudeAA\n",
    "#le dataset Original de 500 insatnces a été split en jeu d'entrainement 80%\n",
    "\n",
    "data_train = pd.read_csv(\"Train_FraudeAA.CSV\")\n",
    "data_test = pd.read_csv(\"Test_FraudeAA.CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation des variables qualitatives (object) en type vecteur nombre. \n",
    "Exigence de scikit-learn\n",
    "\n",
    "Au lieu de passer par l'encoder OnehotEncoder, voici une approche plus simple dans ce contexte de l'exemple\n",
    "C'est d'utiliser la fonction get_dummy() de pandas qui produit le même résultat que l'encoder OneHotEncoder..\n",
    "\n",
    "Nous avons 2 variables qualitatives:\n",
    "1. InjuryType = BrokenLimb,Soft Tissue,Back,Serious\n",
    "2. OvernightHospitalStay=yes/no\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouv_df_train=pd.get_dummies(data_train[data_train.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous allons compléter le dataFrame nouv_df avec la variable cible dont le nom\n",
    "#doit être class\n",
    "nouv_df_train['class'] = data_train['Fraude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer des données des variables prédictives (X) \n",
    "# de la variable cible (Y)\n",
    "X_train=nouv_df_train.iloc[:,:-1]\n",
    "y_train=nouv_df_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation au cas ou\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le temps d'entrainement en secondes 10.74462418483876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#importation du module mlp\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#utilsation 2 couches cachées. La premiere est composé de 100 neurones et l'autre de 50.\n",
    "#la fonction d'activation est le relu\n",
    "#la regle d'apprentissage est la descente du gradient: solver=sgd\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, 50), solver='sgd', max_iter=12500, activation='relu', random_state=1)\n",
    "\n",
    "#mesure du temps courant\n",
    "tc = clock()\n",
    "clf.fit(X_train,y_train)\n",
    "tt = clock()\n",
    "print(\"le temps d'entrainement en secondes\", tt-tc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation avec un jeu de test\n",
    "\n",
    "Validation du classeur clf avec le jeu de test.\n",
    "Il faut s'assurer que le jeu de test est dans la même configuration\n",
    "que le jeu d'entrainement.\n",
    "Étant que nous avons transformé les variables qualitativesen en nombre,\n",
    "Dans le jeu d'entrainement:\n",
    "1.InjuryType = BrokenLimb,Soft Tissue,Back,Serious\n",
    "2.OvernightHospitalStay=yes/no\n",
    "Il faut faire la même chose dans le cas de jeu de test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouv_df_test=pd.get_dummies(data_test[data_test.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#il faut aussi renommer la variable cible\n",
    "# et comme la variable cible est nommée Fraude, il faut aussi la renommer en class\n",
    "nouv_df_test['class'] = data_test['Fraude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#séparons les donnees de test des variables prédictives de celles \n",
    "#de la variable cible et normaliser aussi.\n",
    "\n",
    "X_test=nouv_df_test.iloc[:,:-1]\n",
    "y_test=nouv_df_test['class']\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Voici un exemple de résultat de test avec le modele clf obtenu initialement \n",
    "# testé avec les données de test\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# le taux de détection est de l'ordre de :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=MLPClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(50, 50),\n",
       "                                                               (100, 100),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'adaptive'],\n",
       "                                        'max_iter': [100, 2500],\n",
       "                                        'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calibarage du MLP pour la recherche des valeurs optimales des hyperparamètres:\n",
    "#nombre de couches cachées et le nombre de neurones associées : tuples : ()\n",
    "#la meilleure fonction d'activation entre le relu, la tengente hyperbolique\n",
    "#la meilleure regle d'apprentissage\n",
    "#le nombre d'iteration\n",
    "#le pas d'apprentissage\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50), (100, 100), (50,100,50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'max_iter':[100,2500],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "clf = RandomizedSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "#clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'solver': 'adam', 'max_iter': 2500, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100), 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "# meilleur parametre\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        56\n",
      "           1       0.92      0.97      0.95        36\n",
      "\n",
      "    accuracy                           0.96        92\n",
      "   macro avg       0.95      0.96      0.95        92\n",
      "weighted avg       0.96      0.96      0.96        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on passe de 93% à 95% : u une bonne amélioration..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {
   "height": "309px",
   "width": "468px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
